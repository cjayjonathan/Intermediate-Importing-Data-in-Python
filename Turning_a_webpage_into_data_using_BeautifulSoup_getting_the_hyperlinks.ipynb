{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Turning a webpage into data using BeautifulSoup: getting the hyperlinks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxZt2S/YO79i5iIMSKTs9j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cjayjonathan/Intermediate-Importing-Data-in-Python/blob/main/Turning_a_webpage_into_data_using_BeautifulSoup_getting_the_hyperlinks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSDiWB253gVY",
        "outputId": "74ef53f8-78a9-43a2-ae8b-6a1857738eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<title>Guido's Personal Home Page</title>\n",
            "pics.html\n",
            "pics.html\n",
            "http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\n",
            "images/df20000406.jpg\n",
            "http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\n",
            "http://www.python.org\n",
            "Resume.html\n",
            "Publications.html\n",
            "bio.html\n",
            "http://legacy.python.org/doc/essays/\n",
            "http://legacy.python.org/doc/essays/ppt/\n",
            "interviews.html\n",
            "pics.html\n",
            "http://neopythonic.blogspot.com\n",
            "http://www.artima.com/weblogs/index.jsp?blogger=12088\n",
            "https://twitter.com/gvanrossum\n",
            "Resume.html\n",
            "guido.au\n",
            "http://legacy.python.org/doc/essays/\n",
            "images/license.jpg\n",
            "http://www.cnpbagwell.com/audio-faq\n",
            "http://sox.sourceforge.net/\n",
            "images/internetdog.gif\n"
          ]
        }
      ],
      "source": [
        "# Import packages\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Specify url\n",
        "url = 'https://www.python.org/~guido/'\n",
        "\n",
        "# Package the request, send the request and catch the response: r\n",
        "r = requests.get(url)\n",
        "\n",
        "# Extracts the response as html: html_doc\n",
        "html_doc = r.text\n",
        "\n",
        "# create a BeautifulSoup object from the HTML: soup\n",
        "soup = BeautifulSoup(html_doc)\n",
        "\n",
        "# Print the title of Guido's webpage\n",
        "print(soup.title)\n",
        "\n",
        "# Find all 'a' tags (which define hyperlinks): a_tags\n",
        "a_tags = soup.find_all('a')\n",
        "\n",
        "# Print the URLs to the shell\n",
        "for link in a_tags:\n",
        "    print(link.get('href'))"
      ]
    }
  ]
}